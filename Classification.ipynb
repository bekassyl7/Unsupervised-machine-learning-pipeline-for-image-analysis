{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lRrEVWuuogG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from imutils import paths\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.cm import coolwarm\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import itertools\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from Utils import cmap_map\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "# Initialize keras model for VGG16 architecture\n",
        "model = vgg16.VGG16(include_top=False,weights='imagenet',pooling = 'avg')\n",
        "\n",
        "OUTPUT_DATASET =  \"SEN_DGB\"\n",
        "FOL = \"SEN_DGBR\"\n",
        "RESULTS = \"Results_Classification_Cross_Validation\"\n",
        "NImages = [\"NX_NY_Images_1\", \"length_125\",\"length_100\",\"NX_NY_Images_2\",\"NX_NY_Images_3\",\"NX_NY_Images_4\",\n",
        "            \"NX_NY_Images_5\",\"NX_NY_Images_6\",\"NX_NY_Images_7\",\n",
        "            \"NX_NY_Images_8\", \"NX_NY_Images_9\",\"NX_NY_Images_10\"]\n",
        "\n",
        "Length_Scale = ['150','125','100','75','50','37.5','30','25','21.4','18.75','16.67','15']\n",
        "\n",
        "L=0\n",
        "for split in NImages:\n",
        "    print(\"[INFO] processing '{} folder'...\".format(split))\n",
        "    img_DIR = os.path.sep.join([OUTPUT_DATASET, split])\n",
        "    results_DIR = os.path.sep.join([FOL, RESULTS, split])\n",
        "    if not os.path.exists(results_DIR):\n",
        "        os.makedirs(results_DIR)\n",
        "        \n",
        "    if L==0:\n",
        "        output_txt =  os.path.sep.join([FOL, RESULTS, \"Accuracy.txt\"])\n",
        "        text_file = open(output_txt, \"a\")\n",
        "        text_file.write('{:s}, {:s}, {:s} ,{:s}, {:s} \\n'.format('Length_Scale', 'CV fold', 'Perplexity', \n",
        "                      'Classification Accuracy (Test)',\n",
        "                      'Clustering Accuracy (Train)'))\n",
        "        \n",
        "    dirs = os.listdir(img_DIR)\n",
        "    n_images = len(dirs)\n",
        "    # Define a numpy.ndarray that stores extracted features by VGG16 CNN\n",
        "    features = np.empty([n_images,512])\n",
        "    # Crete an array for the targets and then define the targets\n",
        "    target = np.empty(n_images)\n",
        "    \n",
        "    kf = KFold(n_splits=5, random_state=7, shuffle=True)\n",
        "    \n",
        "    fold=1\n",
        "    for train_index, test_index in kf.split(dirs):\n",
        "        train_dirs = np.array(dirs)[train_index.astype(int)]\n",
        "        test_dirs = np.array(dirs)[test_index.astype(int)]\n",
        "        train_tragets = np.array(target)[train_index.astype(int)]\n",
        "        test_targets = np.array(target)[test_index.astype(int)]\n",
        "        \n",
        "        train_images = len(train_dirs)\n",
        "        test_images = len(test_dirs)\n",
        "        # convert them into a list\n",
        "        targets = list(target)\n",
        "        \n",
        "        # Load images and extract the features with VGG16 for train and test images\n",
        "        i = 0\n",
        "        for item in train_dirs:\n",
        "            img_path = os.path.join(img_DIR,item) \n",
        "            if os.path.isfile(img_path):\n",
        "                filename = item.split(os.path.sep)[-1]\n",
        "                curr_label1 = filename.split('_')[0]\n",
        "                curr_label2 = filename.split('_')[1]\n",
        "                if curr_label1 == \"DF140T\":\n",
        "                    if curr_label2 == \"DGB\":\n",
        "                        target[i]=(0)\n",
        "                    elif curr_label2 == \"SEN\":\n",
        "                        target[i]=1\n",
        "                elif curr_label1 == \"DP980\":\n",
        "                    if curr_label2 == \"DGB\":\n",
        "                        target[i]=2\n",
        "                    elif curr_label2 == \"SEN\":\n",
        "                        target[i]=3\n",
        "                \n",
        "                img = image.load_img(img_path, target_size=(224, 224))\n",
        "                x = image.img_to_array(img)\n",
        "                x = np.expand_dims(x, axis=0)\n",
        "                x = preprocess_input(x)\n",
        "                features[i] = model.predict(x)\n",
        "                i+=1\n",
        "        \n",
        "        for item in test_dirs:\n",
        "           img_path = os.path.join(img_DIR,item) \n",
        "           if os.path.isfile(img_path):\n",
        "               filename = item.split(os.path.sep)[-1]\n",
        "               curr_label1 = filename.split('_')[0]\n",
        "               curr_label2 = filename.split('_')[1]\n",
        "               if curr_label1 == \"DF140T\":\n",
        "                    if curr_label2 == \"DGB\":\n",
        "                        target[i]=(0)\n",
        "                    elif curr_label2 == \"SEN\":\n",
        "                        target[i]=1\n",
        "               elif curr_label1 == \"DP980\":\n",
        "                    if curr_label2 == \"DGB\":\n",
        "                        target[i]=2\n",
        "                    elif curr_label2 == \"SEN\":\n",
        "                        target[i]=3\n",
        "               \n",
        "               img = image.load_img(img_path, target_size=(224, 224))\n",
        "               x = image.img_to_array(img)\n",
        "               x = np.expand_dims(x, axis=0)\n",
        "               x = preprocess_input(x)\n",
        "               features[i] = model.predict(x)\n",
        "               i+=1     \n",
        "    \n",
        "        # K-nearest neighbors parameters\n",
        "        neighbors = 10\n",
        "        weight_option = 'uniform' \n",
        "        #K means parameteres\n",
        "        clusters = 4\n",
        "        \n",
        "        totalImages = len(features)\n",
        "        if totalImages < 50:\n",
        "            n_comp = totalImages\n",
        "        else:\n",
        "            n_comp = 50\n",
        "        \n",
        "        # DImensionality reduction to 50 using PCA\n",
        "        X_pca_50 = PCA(n_components=n_comp).fit_transform(features)\n",
        "        \n",
        "        target_array = np.asarray(target,dtype=np.int8)\n",
        "        # For 4 classes\n",
        "        labels = ['DF140TDGB', 'DF140TSEN', 'DP980DGB', 'DP980SEN']\n",
        "        colors = [0, 1, 2, 3]\n",
        "        \n",
        "        # Implement t-SNE dimensionality reduction for different values of perplexity to obtain the best projection\n",
        "        for p in range(5, 50, 5):\n",
        "            \n",
        "            print('\\n')\n",
        "            print('Perplexity = {}'.format(p))\n",
        "            print('\\n')\n",
        "            \n",
        "            # Take the reduced features by PCA and insert them into t-sne\n",
        "            X_tsne= TSNE(n_components=2, perplexity=p, n_iter=3000, random_state=7, verbose=0).fit_transform(X_pca_50)\n",
        "            \n",
        "            # Separate the train images and their ground truth labels\n",
        "            X_tsne_train = X_tsne[:train_images]\n",
        "            target_train = target_array[:train_images] \n",
        "            \n",
        "            \n",
        "            # Separate the test images and their ground truth labels\n",
        "            X_tsne_test = X_tsne[train_images:]\n",
        "            target_test = target_array[train_images:]\n",
        "            \n",
        "            \n",
        "            # -------------------------------------------------------------------------------------------------------------------------\n",
        "            #   Kmeans labeling\n",
        "            #--------------------------------------------------------------------------------------------------------------------------\n",
        "            \n",
        "            kmeans = KMeans(n_clusters=clusters, init='k-means++', n_init=30, max_iter=1000, \n",
        "                            tol=0.0001, precompute_distances='deprecated', verbose=0, random_state=7, \n",
        "                            copy_x=True, n_jobs='deprecated', algorithm='auto')\n",
        "            kmeans.fit(X_tsne_train)\n",
        "            labs = kmeans.labels_\n",
        "        \n",
        "        \n",
        "            correspond_labels = np.zeros(labs.shape)\n",
        "            # Convert the k-Means labeling into the same colormap labeling as the ground truth labeling    \n",
        "            correspond_labels[labs==0] = np.argmax(np.bincount(target_train[labs==0]))    \n",
        "            correspond_labels[labs==1] = np.argmax(np.bincount(target_train[labs==1]))\n",
        "            correspond_labels[labs==2] = np.argmax(np.bincount(target_train[labs==2]))    \n",
        "            correspond_labels[labs==3] = np.argmax(np.bincount(target_train[labs==3]))\n",
        "        \n",
        "            \n",
        "            # find the errors\n",
        "            l = [k if t==k else max(target_train)+1 for t,k in zip(target_train, correspond_labels)]\n",
        "            l = np.asarray(l,dtype=np.int8)\n",
        "        \n",
        "            # correct indices\n",
        "            cor_idx = l<=max(target_train)    \n",
        "            cor_labels = l[cor_idx]\n",
        "                \n",
        "            X_tsne_train_c = X_tsne_train[cor_idx]  \n",
        "            \n",
        "            kmeans.fit(X_tsne_test)\n",
        "            labs_test = kmeans.labels_\n",
        "        \n",
        "        \n",
        "            correspond_labels_test = np.zeros(labs_test.shape)\n",
        "            # Convert the k-Means labeling into the same colormap labeling as the ground truth labeling    \n",
        "            correspond_labels_test[labs_test==0] = np.argmax(np.bincount(target_test[labs_test==0]))    \n",
        "            correspond_labels_test[labs_test==1] = np.argmax(np.bincount(target_test[labs_test==1]))\n",
        "            correspond_labels_test[labs_test==2] = np.argmax(np.bincount(target_test[labs_test==2]))    \n",
        "            correspond_labels_test[labs_test==3] = np.argmax(np.bincount(target_test[labs_test==3]))\n",
        "        \n",
        "            \n",
        "            # find the errors\n",
        "            l_test = [k if t==k else max(target_test)+1 for t,k in zip(target_test, correspond_labels_test)]\n",
        "            l_test = np.asarray(l_test,dtype=np.int8)\n",
        "        \n",
        "            # correct indices\n",
        "            cor_idx_test = l_test<=max(target_test)    \n",
        "            cor_labels_test = l_test[cor_idx_test]\n",
        "                \n",
        "            X_tsne_test_c = X_tsne_test[cor_idx_test]  \n",
        "        \n",
        "            # -------------------------------------------------------------------------------------------------------------------------\n",
        "            #   K Nearest Neighbors Classifier\n",
        "            #--------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "                        \n",
        "            kmeans_neigh = KNeighborsClassifier(n_neighbors=neighbors,weights=weight_option)\n",
        "            kmeans_neigh.fit(X_tsne_train_c, cor_labels)\n",
        "            \n",
        "            print('\\n')\n",
        "            print('Plotting Decision Boundary')\n",
        "            print('\\n')   \n",
        "            # Plot the decision boundary. For that, we will assign a color to each\n",
        "            x_min, x_max = X_tsne_train_c[:, 0].min() - 20, X_tsne_train_c[:, 0].max() + 20\n",
        "            y_min, y_max = X_tsne_train_c[:, 1].min() - 20, X_tsne_train_c[:, 1].max() + 20\n",
        "            xx, yy = np.meshgrid(np.arange(x_min, x_max, 1),\n",
        "                                  np.arange(y_min, y_max, 1))\n",
        "            xy = np.c_[xx.ravel(), yy.ravel()]\n",
        "            # Predict the label of each mexh point with K-nearest neighbors\n",
        "            knn_labels = kmeans_neigh.predict(xy)\n",
        "    \n",
        "            # Put the result into a color plot\n",
        "            zz = knn_labels.reshape(xx.shape)\n",
        "             \n",
        "            light_brg = cmap_map(lambda x: x/2 + 0.5, matplotlib.cm.brg)\n",
        "            dark_brg = cmap_map(lambda x: x*0.75, matplotlib.cm.brg)        \n",
        "            # Plot the result with scatter\n",
        "            fig1 = plt.figure(figsize=(6, 4))\n",
        "            ax1 = plt.axes(frameon=False)\n",
        "            plt.setp(ax1, xticks=(), yticks=())\n",
        "            plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.9,\n",
        "                            wspace=0.0, hspace=0.0)\n",
        "            mp1 = plt.pcolormesh(xx, yy, zz, cmap=light_brg )\n",
        "            sc1 = plt.scatter(X_tsne_test[:, 0], X_tsne_test[:, 1], c=target_test, marker=\"D\", edgecolors='k', cmap=light_brg)\n",
        "            handles_1 = [plt.plot([],color=mp1.get_cmap()(mp1.norm(c)),ls=\"\", marker=\"o\")[0] for c in colors ]  \n",
        "            plt.tight_layout()\n",
        "            mp1 .set_clip_on(False) \n",
        "\n",
        "            legend1 = ax1.legend(handles_1, labels, loc='best',frameon='True',framealpha=0.5)\n",
        "            ax1.add_artist(legend1)\n",
        "            \n",
        "            #Predict the the response for test dataset\n",
        "            y_pred = kmeans_neigh.predict(X_tsne_test)\n",
        "            \n",
        "            #Import scikit-learn metrics module for accuracy calculation\n",
        "            from sklearn import metrics\n",
        "    \n",
        "            text_file = open(output_txt, \"a\")\n",
        "            text_file.write('{:s}, {:d}, {:d} ,{:.3f}, {:.3f} \\n'.format(Length_Scale[L], fold, p, \n",
        "                         metrics.accuracy_score(target_test, y_pred),\n",
        "                         metrics.accuracy_score(target_train, correspond_labels)))\n",
        "            text_file.close()\n",
        "            \n",
        "            # save the figure with the specific perplexity\n",
        "            out_name = 'KNN_fold_'+ str(fold) + '_perp_' + str(p) + '.png'\n",
        "            plt.savefig(os.path.sep.join([results_DIR, out_name]))\n",
        "            plt.close()\n",
        "        fold+=1\n",
        "    L+=1           \n",
        "            \n",
        " "
      ]
    }
  ]
}