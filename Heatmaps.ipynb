{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heatmaps.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lRrEVWuuogG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from imutils import paths\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.cm import coolwarm\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from keras import models\n",
        "import itertools\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Function for feature extraction from an image\n",
        "def extract_features_vgg16(img):\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    out = model.predict(x)\n",
        "    return out\n",
        "\n",
        "# Initialize keras model for VGG16 architecture\n",
        "model = vgg16.VGG16(include_top=False,weights='imagenet',pooling = 'avg')\n",
        "\n",
        "OUTPUT_DATASET =  \"Cropped_Images_SEN\"\n",
        "FOL = \"SEN\"\n",
        "RESULTS = \"Results_heatmap\"\n",
        "NImages = [\"NX_NY_Images_1\", \"length_125\",\"length_100\",\"NX_NY_Images_2\",\"NX_NY_Images_3\",\"NX_NY_Images_4\",\n",
        "             \"NX_NY_Images_5\",\"NX_NY_Images_6\",\"NX_NY_Images_7\",\n",
        "             \"NX_NY_Images_8\", \"NX_NY_Images_9\",\"NX_NY_Images_10\"]\n",
        "\n",
        "for split in NImages:\n",
        "    print(\"[INFO] processing '{} folder'...\".format(split))\n",
        "    p= os.path.sep.join([OUTPUT_DATASET, split])\n",
        "    results_DIR = os.path.sep.join([FOL, RESULTS, split])\n",
        "    if not os.path.exists(results_DIR):\n",
        "        os.makedirs(results_DIR)\n",
        "    imagePaths = list(paths.list_images(p))\n",
        "    totalImages = len(list(paths.list_images(p)))\n",
        "    if totalImages == 0:\n",
        "        pass\n",
        "    else:\n",
        "        features = np.empty([totalImages,512])    \n",
        "        labels_num = []\n",
        "        i=0\n",
        "        for file in imagePaths:\n",
        "            filename = file.split(os.path.sep)[-1]\n",
        "            filename = file.split(os.path.sep)[-1]\n",
        "            curr_label1 = filename.split('_')[0]\n",
        "            curr_label2 = filename.split('_')[1]\n",
        "            if curr_label1 == \"DF140T\":\n",
        "                labels_num.append(0)\n",
        "            elif curr_label1 == \"DP980\":\n",
        "                labels_num.append(1)\n",
        "                \n",
        "            img = image.load_img(file, target_size=(224, 224))\n",
        "            x = image.img_to_array(img)\n",
        "            x = np.expand_dims(x, axis=0)\n",
        "            x = preprocess_input(x)\n",
        "            features[i] = model.predict(x)\n",
        "            i+=1    \n",
        "\n",
        " \n",
        "        totalImages = len(features)\n",
        "        if totalImages < 50:\n",
        "            n_comp = totalImages\n",
        "        else:\n",
        "            n_comp = 50\n",
        "        # PCA dimensionality reduction to 50 components\n",
        "        pca = PCA(n_components=n_comp) #Cheaper computation of distance matrix \n",
        "        x_pca = pca.fit_transform(features) \n",
        "        PC_comp = 1 \n",
        "        \n",
        "        e_values = pca.explained_variance_\n",
        "                \n",
        "        e_vectors = np.absolute(pca.components_)\n",
        "                \n",
        "        n_major_features = e_vectors[PC_comp,:].shape[0]\n",
        "                                        # Retrieve outputs from the last layers of the model and create a new model that is called activation_model\n",
        "        layer_outputs = [layer.output for layer in model.layers[15:]]\n",
        "        activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "        input_dir = p\n",
        "        dirs = os.listdir(input_dir)\n",
        "                        \n",
        "        # Load the images and compute an Activation Heatmap for each input image\n",
        "        for item in dirs:\n",
        "            # load image\n",
        "            img_path = os.path.join(input_dir,item)\n",
        "            img = image.load_img(img_path,target_size=(224, 224))\n",
        "            x = image.img_to_array(img)\n",
        "            x = np.expand_dims(x, axis=0)\n",
        "            x = preprocess_input(x)\n",
        "                    \n",
        "            # Get the features predicted by VGG16 in the last layers\n",
        "            activations = activation_model.predict(x)\n",
        "            # Then keep only the activations of the last convolutional layers\n",
        "            last_conv_layer_activation = activations[-2]\n",
        "            heatmap = np.zeros(last_conv_layer_activation[0, :, :, 0].shape,dtype = np.float32)\n",
        "            for i in range(n_major_features):\n",
        "                heatmap += last_conv_layer_activation[0, :, :, i]*e_vectors[PC_comp,i]\n",
        "                \n",
        "            heatmap = np.maximum(heatmap, 0)\n",
        "            heatmap /= np.max(heatmap)\n",
        "                                \n",
        "            # Use cv2 to load the original image\n",
        "            img = cv2.imread(img_path)\n",
        "            # Resize the heatmaps and make them RGB\n",
        "            heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))                \n",
        "            heatmap = np.uint8(255 * heatmap)\n",
        "  \n",
        "            # Apply the heatmap to the original image\n",
        "            heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "            out_img = heatmap * 0.4 + img\n",
        "            # Save heatmap\n",
        "            out_file = os.path.join(results_DIR,item)\n",
        "            cv2.imwrite(out_file, out_img)                        "
      ]
    }
  ]
}